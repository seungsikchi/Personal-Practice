import DataProcessing as dp
import matplotlib.pyplot as plt
import numpy as np
import math

from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
from sklearn.model_selection import train_test_split

def Model(inputs=(256, 256, 3)):

    model = tf.keras.Sequential([
        Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=inputs),
        Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),
        MaxPooling2D(pool_size=(2,2)), # 64
        
        Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),
        Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),
        MaxPooling2D(pool_size=(2,2)), # 32

        Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'),
        Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'),
        MaxPooling2D(pool_size=(2,2)), # 16

        Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'),
        Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'),
        MaxPooling2D(pool_size=(2,2)), # 8

        Flatten(),
        Dense(1024, activation='relu'),
        Dense(256, activation='relu'),
        Dense(64, activation='relu'),
        Dense(1)
    ])

    model.compile(optimizer=Adam(), loss='mean_squared_error')
    model.summary()

    return model

def train_model(input_shape, train_x, train_y, epoch):
    model = Model(input_shape) 

    history = model.fit(train_x, train_y, epochs=epoch, validation_split=0.2)
    model.save('../VGG_model.h5')

    plt.figure(figsize = (12,4))
    plt.plot(history.history['loss'], 'b-', label = 'loss')
    plt.plot(history.history['val_loss'], 'r--', label = 'val_loss')
    plt.xlabel('Epochs')
    plt.ylim(0, 0.01)
    plt.legend()

    plt.show()

    return model

def pred_model(trained_model, train_x, test_x, test_y):
    model = trained_model # 이렇게 model을 새로 받으면 가중치 초기화 아닌가? 테스트하기
    train_pred = model.predict(train_x)
    test_pred = model.predict(test_x)
    print(test_pred.shape)
    print(train_pred.shape)
    test_y = test_y * 10 # normalize 풀기
    PH = test_pred * 10

    for i in range(10):
        #print('\n정답 : {}, 예상 : {}'.format(test_y[i], PH[i]))
        print(test_y[i], PH[i][0])

        plt.subplot(1, 10, i+1)
        plt.imshow(test_x[i])
        plt.xlabel(PH[i][0])
        plt.ylabel(test_y[i])

    return train_pred, test_pred

def Scatterplot(train_pred, test_pred, train_y, test_y):

    train_y = train_y * 10
    train_pred = train_pred * 10
    train_y = train_y[0:249]
    train_pred = train_pred[0:249]
    test_y = test_y * 10
    test_pred = test_pred * 10

    plt.figure(figsize = (5,5))
    plt.plot(train_y, train_pred, 'r.', label = 'train_y')
    plt.plot(test_y, test_pred, 'b.', label = 'test_y')
    plt.axis([min(train_y), max(train_y), min(train_y), max(train_y)])

    #y = x에 해당하는 선
    plt.plot([min(train_y), max(train_y)], [min(train_y), max(train_y)], ls="--", c=".3", label = 'y=x')
    plt.xlabel('Actual PH')
    plt.ylabel('pred')
    plt.legend()

    plt.show()

def correlation(train_y, test_y):

    train_Variance = []
    test_Variance = []
    train_Deviation = []
    test_Deviation = []
    Covariance = []

    for i in range(train_y):
        train_sum = train_sum + train_y[i]
    for i in range(test_y):
        test_sum = test_sum + test_y[i]

    train_avarage = train_sum/len(train_y)
    test_avarage = test_sum/len(test_y)

    for i in range(len(train_y)):
        train_Deviation[i] = train_y[i] - train_avarage
    for i in range(len(test_y)):
        test_Deviation[i] = test_y[i] - test_avarage

    for i in range(len(train_y)):
        train_Variance.append((train_y[i] - train_avarage) * (train_y[i] - train_avarage)/len(train_y))
        trainVariance_sum = trainVariance_sum + train_Variance[i]
    for i in range(len(test_y)):
        test_Variance.append((test_y[i] - test_avarage) * (test_y[i] - test_avarage)/len(test_y))
        testVariance_sum = testVariance_sum + test_Variance[i]
    for i in range(len(test_y)):
        Covariance[i] = train_Deviation[i] * test_Deviation[i]/math.sqrt(trainVariance_sum * testVariance_sum)

    plt.figure(figsize = (12,4))

    



path = './train_crop'
dim = 256
pre_p = dp.DataProcessing(path)
train_x, train_y, test_x, test_y = pre_p.load_data(dim)


trained_model = train_model((dim, dim, 3), train_x, train_y, 100)
train_pred, test_pred = pred_model(trained_model, train_x, test_x, test_y)
Scatterplot(train_pred, test_pred, train_y, test_y)
